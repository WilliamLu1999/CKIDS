{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6d5b3e9-326f-4808-b30f-a64ca135d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request \n",
    "import os\n",
    "import glob\n",
    "import os.path\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f106ad6-9395-4b75-9f40-404e642734af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 csv files in the 2022-02 folder\n"
     ]
    }
   ],
   "source": [
    "file_paths=[]\n",
    "# after we loop through the folder and get every csv file, we go inside the csv file and grab links for each csv file\n",
    "path_2022_02 = \"/project/ll_774_951/uk_ru/twitter/data/2022-02/*.csv\"\n",
    "for fname in glob.glob(path_2022_02):\n",
    "    file_paths.append(fname)\n",
    "print(len(file_paths),'csv files in the 2022-02 folder')\n",
    "#file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ffbf72c-8732-4034-a73b-3eabce625912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(path,counter):\n",
    "    # combine all files three columns (media_urls, rt_media_urls, q_media_urls) into one list\n",
    "    # and store it to a csv file\n",
    "    special_char = \",]['\"\n",
    "    image_links=[]\n",
    "    for csv in path: # try 2 files\n",
    "        df = pd.read_csv(csv,engine='python', error_bad_lines=False)\n",
    "        df_urls = df[['media_urls','rt_media_urls','q_media_urls']]\n",
    "        df_all_urls = df_all_urls.melt(value_name='urls')[['urls']] # into single column\n",
    "        download_1 = df_all_urls.loc[df_all_urls.urls.str.contains('http', na=False)]\n",
    "        download_list_1 = download_1[\"urls\"].tolist()\n",
    "        downloads_1 = [''.join(x for x in string if not x in special_char) for string in download_list_1]\n",
    "        downloads_set =set(downloads_1)\n",
    "        downloads_list =list(downloads_set)\n",
    "        image_links.append(downloads_list)\n",
    "    flat_image_links = list(np.concatenate(image_links)) # it was a list of lists\n",
    "    urls_csv_one_column = flat_image_links.to_csv(str(counter)+'.csv')\n",
    "    ## need to change the above line for storing the csv to the correct path on HPC\n",
    "    return urls_csv_one_column # a single list of urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c9dc4ca-0c2e-4f5e-8b92-4c319439fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(one_column_csv):\n",
    "    df = pd.read_csv('/project/ll_774_951/uk_ru/twitter/one_column_urls'+str(one_column_csv)+'.csv')\n",
    "    try:\n",
    "        for link in df:\n",
    "            urllib.request.urlretrieve(link,'/project/ll_774_951/uk_ru/twitter/twitter_images2/'+os.path.basename(link))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b0bf3-6ebf-4e21-9d06-5ae1e95a75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "counter = 0 # define a counter so that we can keep track which csv file we have download already\n",
    "for i in range(0,len(list),batch_size)ï¼š\n",
    "    counter+=1\n",
    "    Batch = file_paths[i:i+batch_size]\n",
    "    single_column_csv=combine_df(Batch,counter)\n",
    "    download(single_column_csv)\n",
    "    print('success'+str(counter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
