{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb8c72c-0041-4252-b42f-77eca19dd9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request \n",
    "import os\n",
    "import glob\n",
    "import os.path\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d1de802-d566-4ed9-85e5-278604397fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 35.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "Successfully installed fsspec-2022.10.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/spack/apps/linux-centos7-x86_64/gcc-8.3.0/python-3.9.2-uvcroioc4witkp6qf7mbebof5ix4wlb6/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip3 install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c17fe3-8b64-4bb0-a320-92825e66ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths=[]\n",
    "# after we loop through the folder and get every csv file, we go inside the csv file and grab links for each csv file\n",
    "path_2022_03 = \"/project/ll_774_951/uk_ru/twitter/data/2022-03/*.csv\"\n",
    "for fname in glob.glob(path_2022_03):\n",
    "    file_paths.append(fname)\n",
    "print(len(file_paths),'csv files in the 2022-03 folder')\n",
    "#file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7053230-191e-4681-af2d-86887f5f82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ath = \"/project/ll_774_951/uk_ru/twitter/data/2022-03/ukraine_russia-2022-03-16-00.csv\"\n",
    "def combine_df(path,counter):\n",
    "    # combine all files three columns (media_urls, rt_media_urls, q_media_urls) into one list\n",
    "    # and store it to a csv file\n",
    "    special_char = \",]['\"\n",
    "    image_links=pd.DataFrame()\n",
    "    for csv in path: # try 2 files\n",
    "        df = pd.read_csv(csv,engine='python', error_bad_lines=False)\n",
    "        df_urls = df[['media_urls','rt_media_urls','q_media_urls']]\n",
    "        df_all_urls = df_urls.melt(value_name='urls')[['urls']] # into single column\n",
    "        download_1 = df_all_urls.loc[df_all_urls.urls.str.contains('http', na=False)]\n",
    "        download_1 = download_1.replace(\"\\[\\'\",'',regex=True)\n",
    "        download_1 = download_1.replace(\"\\'\\]\",'',regex=True)\n",
    "        download_1 = download_1.replace(\"\\,\",'',regex=True)\n",
    "        # download_list_1 = download_1[\"urls\"].tolist()\n",
    "        # downloads_1 = [''.join(x for x in string if not x in special_char) for string in download_list_1]\n",
    "        #downloads_set =set(downloads_1)\n",
    "        #downloads_list =list(downloads_set)\n",
    "        image_links = pd.DataFrame(download_1)\n",
    "        # blankIndex=[''] * len(image_links)\n",
    "        # image_links.index=blankIndex\n",
    "    # flat_image_links = list(np.concatenate(image_links)) # it was a list of lists\n",
    "    # flat_image_links_set = set(flat_image_links)\n",
    "    # flat_image_links_list = list(flat_image_links_set)\n",
    "    # ls_csv_one_column = flat_image_links_list.to_csv(str(counter)+'.csv')\n",
    "    ## need to change the above line for storing the csv to the correct path on HPC\n",
    "    image_links.to_csv('/project/ll_774_951/uk_ru/twitter/one_column_urls/' + str(counter)+'.csv')\n",
    "    return counter # listofurls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315f01b-0d34-45a3-bd37-8d222f059b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(counter):\n",
    "    df = pd.read_csv('/project/ll_774_951/uk_ru/twitter/one_column_urls/'+str(counter)+'.csv')\n",
    "    # df = pd.read_csv('/project/ll_774_951/uk_ru/twitter/one_column_urls/1.csv')\n",
    "    # df_urls = df[['urls']]\n",
    "    # download_1 = df_all_urls.loc[df_all_urls.urls.str.contains('http', na=False)]\n",
    "    # download_list_1 = download_1[\"urls\"].tolist()\n",
    "    # downloads_1 = [''.join(x for x in string if not x in special_char) for string in download_list_1]\n",
    "    # downloads_set =set(downloads_1)\n",
    "    # downloads_list =list(downloads_set)\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(df.loc[i, \"urls\"],'/project/ll_774_951/uk_ru/twitter/twitter_images2/'+os.path.basename(df.loc[i, \"urls\"]))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f75152-1c5e-4ddb-8ecb-1f0597a4305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "counter = 0 # define a counter so that we can keep track which csv file we have download already\n",
    "for i in range(0,len(file_paths),batch_size):\n",
    "    counter+=1\n",
    "    Batch = file_paths[i:i+batch_size]\n",
    "    single_column_csv=combine_df(Batch,counter)\n",
    "    download_images(single_column_csv)\n",
    "    print('success'+str(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c90954-35ec-4c2c-8dcd-631039cb49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/project/ll_774_951/uk_ru/twitter/data/2022-03/ukraine_russia-2022-03-16-00.csv', engine='python', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "303b894c-2e1f-4701-b603-d1ee32b08518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      urls\n",
      "23          http://pbs.twimg.com/media/FN7dxHOWUAAVya1.png\n",
      "115      http://pbs.twimg.com/tweet_video_thumb/FN7eKtZ...\n",
      "123         http://pbs.twimg.com/media/FN7eR5KXwAEcCfB.jpg\n",
      "309         http://pbs.twimg.com/media/FN5l477XoAszsiM.jpg\n",
      "315         http://pbs.twimg.com/media/FN7dlSmWQAU7F0Z.jpg\n",
      "...                                                    ...\n",
      "1066226  http://pbs.twimg.com/amplify_video_thumb/15036...\n",
      "1066236  http://pbs.twimg.com/ext_tw_video_thumb/150388...\n",
      "1066244     http://pbs.twimg.com/media/FNuL8iVXMAQfMUs.jpg\n",
      "1066306  http://pbs.twimg.com/ext_tw_video_thumb/150382...\n",
      "1066320     http://pbs.twimg.com/media/FNuL8iVXMAQfMUs.jpg\n",
      "\n",
      "[71290 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "image_links=pd.DataFrame()\n",
    "special_char = \",]['\"\n",
    "\n",
    "df_urls = df[['media_urls','rt_media_urls','q_media_urls']]\n",
    "df_all_urls = df_urls.melt(value_name='urls')[['urls']] # into single column\n",
    "download_1 = df_all_urls.loc[df_all_urls.urls.str.contains('http', na=False)]\n",
    "download_1 = download_1.replace(\"\\[\\'\",'',regex=True)\n",
    "download_1 = download_1.replace(\"\\'\\]\",'',regex=True)\n",
    "download_1 = download_1.replace(\"\\,\",'',regex=True)\n",
    "        # download_list_1 = download_1[\"urls\"].tolist()\n",
    "        # downloads_1 = [''.join(x for x in string if not x in special_char) for string in download_list_1]\n",
    "        #downloads_set =set(downloads_1)\n",
    "        #downloads_list =list(downloads_set)\n",
    "#image_links.append(download_1, ignore_index=True)\n",
    "image_links = pd.DataFrame(download_1)\n",
    "# image_links['urls'] = image_links['urls'].map(lambda x: x.lstrip(',').rstrip(','))\n",
    "# blankIndex=[''] * len(image_links)\n",
    "# image_links.index=blankIndex\n",
    "    # flat_image_links = list(np.concatenate(image_links)) # it was a list of lists\n",
    "    # flat_image_links_set = set(flat_image_links)\n",
    "    # flat_image_links_list = list(flat_image_links_set)\n",
    "    # ls_csv_one_column = flat_image_links_list.to_csv(str(counter)+'.csv')\n",
    "    ## need to change the above line for storing the csv to the correct path on HPC\n",
    "# image_links.to_csv('/project/ll_774_951/uk_ru/twitter/one_column_urls/' + str(counter)+'.csv')\n",
    "print(image_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0bd33-3c3e-4849-8b70-040ad6cb65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = pd.read_csv('/project/ll_774_951/uk_ru/twitter/one_column_urls/1.csv')\n",
    "    # df = pd.read_csv('/project/ll_774_951/uk_ru/twitter/one_column_urls/1.csv')\n",
    "    # df_urls = df[['urls']]\n",
    "    # download_1 = df_all_urls.loc[df_all_urls.urls.str.contains('http', na=False)]\n",
    "    # download_list_1 = download_1[\"urls\"].tolist()\n",
    "    # downloads_1 = [''.join(x for x in string if not x in special_char) for string in download_list_1]\n",
    "    # downloads_set =set(downloads_1)\n",
    "    # downloads_list =list(downloads_set)\n",
    "    for i in range(len(df)):\n",
    "        print(df.loc[i, \"urls\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaff1c3-cfab-44b0-960b-9c2526c13285",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = df['tweetid']\n",
    "tweet_id = tweet_id.dropna()\n",
    "# for i in tweet_id:\n",
    "#     url = \"https://twitter.com/anyuser/status/\" + i\n",
    "print(tweet_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
